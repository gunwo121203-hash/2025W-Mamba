# SwiFT: Swin 4D fMRI Transformer 논문 정리

## 📋 목차
1. [배경 및 문제 정의](#배경-및-문제-정의)
2. [SwiFT 개요](#swift-개요)
3. [핵심 아키텍처](#핵심-아키텍처)
4. [주요 메커니즘](#주요-메커니즘)
5. [자기 지도 사전 학습](#자기-지도-사전-학습)
6. [실험 및 결과](#실험-및-결과)
7. [기존 방법론과의 비교](#기존-방법론과의-비교)

---

## 배경 및 문제 정의

### 🔴 기존 fMRI 분석 방법의 한계

| 방법론        | 정의                                                  | 장점             | 한계                                                                           |
| ------------- | ----------------------------------------------------- | ---------------- | ------------------------------------------------------------------------------ |
| **ROI-based** | 고차원 fMRI(약 30만 복셀) → 수백 개 ROIs로 축소       | 계산 효율성 높음 | • 수동 설계 특징 사용<br>• 개별 뇌의 미묘한 차이 손실<br>• 필수 정보 손실 위험 |
| **Two-step**  | 원본 fMRI 사용, 공간/시간 특징을 별도 아키텍처로 학습 | -                | • 시공간 정보 포착 능력 제한<br>• 통합적 모델링 어려움                         |

### 🎯 SwiFT의 해결 방안

> **"Swin Transformer 아키텍처의 4D 확장인 SwiFT는 고차원 fMRI에서 직접 뇌의 고유 활동에 대한 시공간적 표현을 종단간 방식으로 공동 학습할 수 있습니다"**

| 핵심 특징                      | 설명                                                     |
| ------------------------------ | -------------------------------------------------------- |
| **End-to-end Learning**        | fMRI 볼륨 직접 입력 → 특징 추출부터 예측까지 통합 학습   |
| **4D 시공간 데이터 직접 처리** | 메모리와 연산 효율성 향상 설계                           |
| **최초의 4D 적용**             | Swin Transformer 기반 4D 시공간 뇌 기능 데이터 처리 모델 |

---

## SwiFT 개요

### ✨ 주요 특징

| 특징                             | 설명                                     | 효과                                                     |
| -------------------------------- | ---------------------------------------- | -------------------------------------------------------- |
| **4DW-MSA**                      | 4D 윈도우 기반 Multi-Head Self-Attention | • 지역적 관계 학습<br>• 계산 복잡도 감소                 |
| **절대 위치 임베딩**             | 토큰의 절대 시간/공간 위치 정보          | • 상대 위치보다 비용 효율적<br>• 시공간 동역학 패턴 인식 |
| **Self-supervised Pre-training** | Contrastive Loss 기반 사전 학습          | 다운스트림 태스크 성능 향상                              |
| **Explainable AI**               | IG-SQ 기법으로 뇌 영역 식별              | 생물학적 의미 해석 가능                                  |

### 📊 평가 데이터셋 및 태스크

| 데이터셋 | 설명                                   | 태스크                | 결과                     |
| -------- | -------------------------------------- | --------------------- | ------------------------ |
| **HCP**  | Human Connectome Project               | 성별, 나이, 인지 지능 |                          |
| **ABCD** | Adolescent Brain Cognitive Development | 성별, 나이, 인지 지능 | **최신 SOTA 모델보다**   |
| **UKB**  | UK Biobank                             | 유동 지능             | **일관되게 우수한 성능** |

---

## 핵심 아키텍처

### 🏗️ SwiFT 전체 구조

```
4D fMRI Image (T×H×W×D×1)
    ↓
Patch Partitioning (6×6×6 패치)
    ↓
┌─────────────────────────────────────┐
│ Stage 1: Linear + Positional Embed  │
│ [4D Swin Block × L₁=2]              │
└─────────────────────────────────────┘
    ↓
┌─────────────────────────────────────┐
│ Stage 2: Patch Merging + Embed     │
│ [4D Swin Block × L₂=2]              │
└─────────────────────────────────────┘
    ↓
┌─────────────────────────────────────┐
│ Stage 3: Patch Merging + Embed     │
│ [4D Swin Block × L₃=6]              │
└─────────────────────────────────────┘
    ↓
┌─────────────────────────────────────┐
│ Stage 4: Global Attention × L₄=2   │
└─────────────────────────────────────┘
    ↓
Classification/Regression Head
```

### 📐 Stage별 상세

| Stage   | 입력 처리                                                                           | 출력             | 블록 수    |
| ------- | ----------------------------------------------------------------------------------- | ---------------- | ---------- |
| **1**   | Patch Partitioning (6×6×6)<br>Linear Embedding (C차원)<br>Positional Embedding      | C차원 토큰       | L₁ = 2     |
| **2-3** | Patch Merging (2×2×2=8개 병합)<br>해상도 ↓, 채널 ↑ (C → 2C)<br>Positional Embedding | 2C차원 토큰      | L₂=2, L₃=6 |
| **4**   | Global Attention<br>(토큰 수 크게 감소)                                             | 전역 시공간 관계 | L₄ = 2     |

### 🔄 4D Swin Transformer Block

```
입력 z_{l-1}
    ↓
┌─────────────────────────────┐
│ LayerNorm                    │
│ 4DW-MSA                      │ ← Window Attention
│ Residual (+ z_{l-1}) → ẑ_l   │
│ LayerNorm                    │
│ MLP                          │
│ Residual (+ ẑ_l) → z_l       │
└─────────────────────────────┘
    ↓
┌─────────────────────────────┐
│ LayerNorm                    │
│ 4DSW-MSA                     │ ← Shifted Window Attention
│ Residual (+ z_l) → ẑ_{l+1}  │
│ LayerNorm                    │
│ MLP                          │
│ Residual (+ ẑ_{l+1}) → z_{l+1}│
└─────────────────────────────┘
```

**수식:**
```
ẑ_l = 4DW-MSA(LN(z_{l-1})) + z_{l-1}
z_l = MLP(LN(ẑ_l)) + ẑ_l
ẑ_{l+1} = 4DSW-MSA(LN(z_l)) + z_l
z_{l+1} = MLP(LN(ẑ_{l+1})) + ẑ_{l+1}
```

---

## 주요 메커니즘

### 1️⃣ 4DW-MSA vs 4DSW-MSA

| 구분            | 4DW-MSA                             | 4DSW-MSA                                            |
| --------------- | ----------------------------------- | --------------------------------------------------- |
| **윈도우 분할** | 고정된 겹치지 않는 윈도우 (P×M×M×M) | 윈도우를 (P/2, M/2, M/2, M/2)만큼 순환 이동 후 분할 |
| **목적**        | 지역적(Local) 관계 학습             | 윈도우 간 상호작용(Cross-window)                    |
| **효과**        | • 계산 효율성<br>• 지역 시공간 패턴 | • 경계 너머 관계 학습<br>• 장거리 의존성 보조       |
| **문제점**      | 윈도우 간 정보 교환 불가            | -                                                   |

### 📊 Shifted-window 과정

```
[1단계] 초기 윈도우 분할 (W-MSA)
┌─────┬─────┐
│ W₁  │ W₂  │  → 각 윈도우 내에서만 Attention
├─────┼─────┤
│ W₃  │ W₄  │
└─────┴─────┘

[2단계] 윈도우 이동 (Cyclic Shift)
    ↓ (P/2, M/2, M/2, M/2) 이동
┌─────┬─────┐
│ W₄  │ W₃  │  → 순환 이동 (끝→처음)
├─────┼─────┤
│ W₂  │ W₁  │
└─────┴─────┘

[3단계] 새로운 윈도우 분할 (SW-MSA)
┌─────┬─────┐
│ W'₁ │ W'₂ │  → 인접 토큰들이 함께 묶임
├─────┼─────┤
│ W'₃ │ W'₄ │  → 경계 너머 정보 교환 가능
└─────┴─────┘
```

### 2️⃣ 패치 병합 (Patch Merging)

| 단계             | 과정                       | 결과              |
| ---------------- | -------------------------- | ----------------- |
| **1. 초기 상태** | C차원 토큰들               | 각 토큰: C개 특징 |
| **2. 그룹화**    | 인접한 2×2×2=8개 토큰 묶기 | 8C차원 벡터       |
| **3. 선형 변환** | FC 레이어 (8C → 2C)        | 2C차원 토큰       |

**효과:**
- 공간 해상도: **절반으로 감소** (토큰 수 ↓)
- 채널 수: **2배 증가** (C → 2C)
- 더 넓은 영역의 정보가 압축된 추상적 특징

### 3️⃣ 절대 위치 임베딩

| 구분                  | 설명                                                                         |
| --------------------- | ---------------------------------------------------------------------------- |
| **필요성**            | Transformer는 permutation-invariant → 순서 정보 필요                         |
| **구현**              | 시간 임베딩 + 공간 임베딩을 브로드캐스팅으로 더함                            |
| **형태**              | 시간: (1×H'×W'×D'×C')<br>공간: (T×1×1×1×C')                                  |
| **효과**              | • 정확한 위치/시간 정보 제공<br>• 동역학 패턴 인식<br>• 상대 위치보다 효율적 |
| **Shifted-window 시** | 위치 값은 변하지 않음 (절대 위치 고정)                                       |

**브로드캐스팅 예시:**
```
입력: (T, H, W, D, C)
시간 임베딩: (1, H, W, D, C) → 각 시간 프레임에 동일
공간 임베딩: (T, 1, 1, 1, C) → 각 공간 위치에 동일
→ 자동 확장되어 더해짐
```

---

## 자기 지도 사전 학습

### 🎯 목적
대규모 fMRI 데이터에서 **일반적인 시공간적 특징** 학습 → 다운스트림 태스크 성능 향상

### 📚 대비 학습 (Contrastive Learning)

| 개념             | 설명                                              |
| ---------------- | ------------------------------------------------- |
| **목표**         | "유사한 것들은 가깝게, 유사하지 않은 것들은 멀리" |
| **거리 측정**    | 코사인 유사도 (-1 ~ 1)                            |
| **h 값**         | `h = e^(cosine_similarity)` (항상 양수)           |
| **Softmax 유사** | 분모: 모든 쌍의 h 합<br>분자: 긍정 쌍의 h         |

### 📊 두 가지 손실 함수

| 손실 함수                         | 목적             | 긍정 쌍                      | 부정 쌍                     |
| --------------------------------- | ---------------- | ---------------------------- | --------------------------- |
| **LIC**<br>(Instance Contrastive) | 다른 피험자 구별 | 동일 피험자의 두 하위 시퀀스 | 다른 피험자들의 하위 시퀀스 |
| **LLL**<br>(Local-local Temporal) | 시간 스탬프 구별 | 동일 시퀀스의 증강 버전      | 동일 피험자의 다른 시퀀스   |

**학습 효과:**
- **LIC**: 피험자별 고유 뇌 활동 패턴 학습
- **LLL**: 시간에 따른 뇌 활동 변화 패턴 학습

### 🔄 미세 조정 (Fine-tuning)

```
[사전 학습]
대규모 fMRI 데이터
    ↓
일반적인 시공간 특징 학습
    ↓
기초 모델 (Foundation Model)
    ↓
[미세 조정]
특정 태스크 데이터 (소량)
    ↓
태스크별 성능 최적화
```

**효과:** 대규모 데이터의 일반 지식 → 특정 작업에 효과적 적용

---

## 실험 및 결과

### 📊 데이터셋

| 데이터셋 | 전처리                                                  | 형식     | 입력                 |
| -------- | ------------------------------------------------------- | -------- | -------------------- |
| **ABCD** | fMRIprep<br>(편향 필드 감소, 두개골 제거, 정렬, 정규화) | 96×96×96 | 20프레임 하위 시퀀스 |
| **HCP**  | 표준 전처리                                             | 96×96×96 | 20프레임 하위 시퀀스 |
| **UKB**  | 표준 전처리                                             | 96×96×96 | 20프레임 하위 시퀀스 |

### ⚙️ 모델 설정

| 파라미터    | 값                              |
| ----------- | ------------------------------- |
| 레이어 수   | {L₁, L₂, L₃, L₄} = {2, 2, 6, 2} |
| 윈도우 크기 | P = M = 4                       |
| 입력 시퀀스 | 20프레임                        |

### 📈 성능 결과

#### 모델 효율성 (TFF 대비)

| 지표               | SwiFT | TFF          | 개선             |
| ------------------ | ----- | ------------ | ---------------- |
| **파라미터**       | 기준  | 158.4배 많음 | **158.4배 적음** |
| **멀티-애드 연산** | 기준  | 15.5배 많음  | **15.5배 적음**  |
| **처리 속도**      | 기준  | 1.94배 느림  | **1.94배 빠름**  |

**결론:** SwiFT가 **계산 효율성이 훨씬 높으며 더 나은 성능** 달성

#### 성능 요약
- 최신 SOTA 모델들보다 **일관되게 우수한 성능**
- ROI 기반 및 2단계 기반 방법 능가
- 대조 사전 학습이 다운스트림 성능 향상에 효과적

### 🔬 해석 가능한 AI (Explainable AI)

#### 방법론: IG-SQ
- **IG (Integrated Gradients)**: 입력 특징의 기여도 계산 (그래디언트 적분)
- **Smoothgrad**: 노이즈 추가 버전들의 평균으로 부드러운 중요도 지도 생성

#### 성별 분류에 중요한 뇌 영역 (연령대별)

| 연령대     | 데이터셋 | 주요 뇌 영역                                         |
| ---------- | -------- | ---------------------------------------------------- |
| **어린이** | ABCD     | mPFC, PCC, PCu, 두정엽<br>→ **디폴트 모드 네트워크** |
| **청년**   | HCP      | 어린이와 유사 + mPFC 강한 활성도<br>시상, 뇌섬엽     |
| **중장년** | UKB      | 하측두회, 내측 안와전두엽<br>→ 가장 높은 IG 값       |

**의의:** 기존 뇌 성별 차이 연구와 일치 → **생물학적 의미 있는 특징 학습** 입증

---

## 기존 방법론과의 비교

### 🔄 관련 연구

| 연구 유형            | 접근 방식                                                                            | 한계             |
| -------------------- | ------------------------------------------------------------------------------------ | ---------------- |
| **최근 연구**        | • 요약된 fMRI 시계열 데이터 활용<br>• 공간/시간 Attention 분리<br>• Window 개념 도입 | 2D/3D에서만 수행 |
| **Swin Transformer** | Shifted window + 패치 병합 제시                                                      | -                |
| **SwiFT**            | **4D 기능적 뇌 영상에 최초 적용**<br>End-to-end 4D 시공간 데이터 처리                | -                |

### 📊 베이스라인 모델

| 카테고리     | 모델                                       | 설명                      |
| ------------ | ------------------------------------------ | ------------------------- |
| **ROI 기반** | BrainNetCNN<br>VanillaTF<br>BNT<br>XGBoost | 전통적 방법               |
| **Two-step** | TFF                                        | 원시 fMRI 입력 트랜스포머 |

**SwiFT의 우위:**
- ROI 기반 및 2단계 기반 방법을 **일관되게 능가**
- TFF 대비 **훨씬 적은 메모리와 훈련 시간**

---

## 결론

### 🎯 핵심 기여

1. **고차원 4D 뇌 기능 MRI를 위한 효율적인 트랜스포머 모델**
   - 시공간 역학 학습 및 생물학적/인지적 결과 예측

2. **다양한 작업에서 최첨단 성능 달성**
   - ROI 기반 및 2단계 기반 방법 능가
   - TFF 대비 효율성 우수

3. **4D 시공간 뇌 기능 데이터를 End-to-end 방식으로 처리하는 최초의 Swin Transformer 아키텍처**

### 🔮 향후 연구 방향

- 대조 사전 학습 효과에 대한 광범위한 조사
- 다양한 다운스트림 태스크 성능 평가
- 해석 가능한 AI 기법을 통한 뇌 기능 이해 심화

---

**작성일**: 2025년  
**논문**: SwiFT: Swin 4D fMRI Transformer
